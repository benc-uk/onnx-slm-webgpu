# Phi-3 Mini Web App using ONNX Web Runtime

## Description

This project is a mini vanilla JS web application that utilizes the ONNX Web Runtime to perform model inference directly in the browser. The application demonstrates the capabilities of using WebGPU and ONNX models on the client side.

It doesn't use transformers.js and uses the ONNX API directly

It's _heavily_ based on this example https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat

## Running Locally

Download the models by running from the repo root

```bash
./get-models.sh
```
